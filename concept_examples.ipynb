{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of how to build concept-based explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and list modules to find where to split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('transformer', GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D(nf=2304, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=768)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D(nf=3072, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=3072)\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")), ('lm_head', Linear(in_features=768, out_features=50257, bias=False))]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(list(model.named_children()))\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the model using the `ModelWithSplitPoints` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreto.commons import ModelWithSplitPoints\n",
    "\n",
    "splitted_model = ModelWithSplitPoints(\n",
    "    model_or_repo_id=\"gpt2\",\n",
    "    split_points=\"transformer.h.1.mlp\",\n",
    "    model_autoclass=AutoModelForCausalLM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and compute activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "rotten_tomatoes = load_dataset(\"cornell-movie-review-data/rotten_tomatoes\")['train']['text']\n",
    "\n",
    "activations = splitted_model.get_activations(rotten_tomatoes[1000:])\n",
    "\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and fit the concept explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonin.poche/interpreto/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from interpreto.concepts import ICAConcepts\n",
    "\n",
    "concept_explainer = ICAConcepts(splitted_model, nb_concepts=10)\n",
    "\n",
    "concept_explainer.fit(activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreto.concepts.interpretations import Granularities, InterpretationSources, TopKInputs\n",
    "\n",
    "some_words = [\n",
    "    \"excellent\", \"amazing\", \"fantastic\", \"outstanding\", \"great\",\n",
    "    \"perfect\", \"wonderful\", \"superb\", \"love\", \"loved\",\n",
    "    \"satisfied\", \"recommend\", \"best\", \"delightful\", \"pleasant\",\n",
    "    \"enjoyed\", \"happy\", \"awesome\", \"brilliant\", \"incredible\",\n",
    "    \"flawless\", \"impressive\", \"top-notch\", \"well-done\", \"five stars\",\n",
    "    \"worth it\", \"will buy again\", \"high quality\", \"fast delivery\", \"friendly\"\n",
    "    \"terrible\", \"awful\", \"bad\", \"poor\", \"disappointing\",\n",
    "    \"hate\", \"horrible\", \"worst\", \"boring\", \"rude\",\n",
    "    \"unsatisfied\", \"never again\", \"waste\", \"problem\", \"issue\",\n",
    "    \"slow\", \"cheap\", \"low quality\", \"broken\", \"not recommended\",\n",
    "    \"annoying\", \"frustrating\", \"one star\", \"unacceptable\", \"defective\",\n",
    "    \"dirty\", \"late delivery\", \"noisy\", \"difficult\", \"didn't work\"\n",
    "]\n",
    "\n",
    "interpretations = concept_explainer.interpret(\n",
    "    TopKInputs,\n",
    "    concepts_indices=\"all\",\n",
    "    source=InterpretationSources.INPUTS,\n",
    "    granularity=Granularities.TOKENS,\n",
    "    inputs=some_words,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0: {'onder': 1.7090288400650024, 'ful': 1.6273586750030518, 'ied': 1.359918236732483, 'ed': 1.2922464609146118, 'ude': 1.2332704067230225}\n",
      "Concept 1: {'top': 13.391587257385254, 'dis': 10.805965423583984, 'didn': 8.963983535766602, 'br': 7.61521053314209, 'worth': 7.578242301940918}\n",
      "Concept 2: {'ude': -1.0211806297302246, 'acceptable': -1.0793287754058838, 'aw': -1.0856738090515137, 'isy': -1.1359949111938477, 'azing': -1.1628979444503784}\n",
      "Concept 3: {'high': 3.893566608428955, 'fl': 3.5968098640441895, 'inc': 3.3934872150421143, 'ex': 3.312361717224121, 'fr': 3.283090114593506}\n",
      "Concept 4: {'Ġdelivery': 1.8142285346984863, 'dis': 1.7381315231323242, 'azing': 1.6744166612625122, 'acceptable': 1.648449420928955, 'Ġit': 1.5403884649276733}\n",
      "Concept 5: {'friendly': 10.231117248535156, 'hor': 9.910233497619629, 'br': 9.903297424316406, 'aw': 9.84243106842041, 'inc': 9.8255615234375}\n",
      "Concept 6: {'Ġwork': 1.7911837100982666, \"'t\": 1.4406126737594604, 'astic': 1.2444143295288086, 'friendly': 1.0949504375457764, 'didn': 1.0563830137252808}\n",
      "Concept 7: {'top': 3.276317834854126, 'dis': 3.1901159286499023, 'iant': 2.3792617321014404, 'ter': 1.5474810600280762, 'aw': 1.5181249380111694}\n",
      "Concept 8: {'top': 11.198465347290039, 'dis': 10.983575820922852, 'br': 6.606813430786133, 'bor': 6.409381866455078, 'ter': 6.370485305786133}\n",
      "Concept 9: {'friendly': 1.5905860662460327, 'hor': 1.232302188873291, 'not': 1.1929970979690552, 'fr': 0.839867353439331, 'broken': 0.770174503326416}\n"
     ]
    }
   ],
   "source": [
    "for concept_id, words_importance in interpretations.items():\n",
    "    print(f\"Concept {concept_id}: {words_importance}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
